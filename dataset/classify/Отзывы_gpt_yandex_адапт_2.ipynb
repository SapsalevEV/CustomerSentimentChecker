{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XHnRsQBIYzQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_D_rl-idKll",
        "outputId": "6270f56f-93f0-41a7-828e-006343910e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shFkyxqudnRT"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Получаем токен и url api\n",
        "YANDEX_CLOUD_API_KEY  = userdata.get('YA_GPT_API_KEY')\n",
        "YANDEX_CLOUD_FOLDER = \"b1gp3qnjq6rhh31ttqqq\"\n",
        "ya_api_url= \"https://llm.api.cloud.yandex.net/v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKmZfpoy06Ot"
      },
      "outputs": [],
      "source": [
        "#from yandex_chain import YandexLLM, ChatYandexGPT\n",
        "from langchain_core.messages import HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2pHU9NJ7dGu"
      },
      "outputs": [],
      "source": [
        "#gpt = YandexLLM(folder_id=YANDEX_CLOUD_FOLDER, api_key=YANDEX_CLOUD_API_KEY)\n",
        "#print(gpt('Привет! Придумай 10 новых слов для приветствия.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfDIBtkTJToq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlcfbxu6IcGh"
      },
      "outputs": [],
      "source": [
        "# режим чата\n",
        "#gpt = ChatYandexGPT(folder_id=YANDEX_CLOUD_FOLDER, api_key=YANDEX_CLOUD_API_KEY)\n",
        "# print(gpt(\n",
        "#     [\n",
        "#         SystemMessage(content='Ты полезный ассистент'),\n",
        "#         HumanMessage(content='Сколько планет в солнечной системе')\n",
        "#     ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRRe7-Tf99ly"
      },
      "outputs": [],
      "source": [
        "# Установка необходимых библиотек (если нужно)\n",
        "\n",
        "# Импорт\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w64gSRky1Xsk"
      },
      "outputs": [],
      "source": [
        "#загрузка csv\n",
        "def upload_csv():\n",
        "    \"\"\"\n",
        "    Загружает CSV-файл через интерфейс Colab.\n",
        "    :return: Путь к загруженному файлу\n",
        "    \"\"\"\n",
        "    print(\"Загрузите CSV-файл...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        raise FileNotFoundError(\"Файл не был загружен.\")\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    print(f\"Файл '{filename}' успешно загружен.\")\n",
        "    return filename\n",
        "\n",
        "def load_csv_to_dataframe(filepath):\n",
        "    \"\"\"\n",
        "    Читает CSV-файл в pandas DataFrame.\n",
        "    :param filepath: Путь к файлу\n",
        "    :param encoding: Кодировка файла\n",
        "    :return: DataFrame\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath, on_bad_lines='skip', sep=None, engine='python')\n",
        "        print(f\"Файл успешно прочитан. Размер: {df.shape}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Ошибка при чтении CSV: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8VQQGIA0h-V"
      },
      "outputs": [],
      "source": [
        "# извлечение списка отзывов\n",
        "def extract_reviews(df, text_column=\"review_text\"):\n",
        "    \"\"\"\n",
        "    Извлекает список отзывов из указанного столбца.\n",
        "    :param df: DataFrame\n",
        "    :param text_column: Название столбца с текстом отзыва\n",
        "    :return: Список строк (отзывов)\n",
        "    \"\"\"\n",
        "    if text_column not in df.columns:\n",
        "        raise ValueError(f\"Столбец '{text_column}' не найден в данных. Доступные: {list(df.columns)}\")\n",
        "\n",
        "    reviews = df[text_column].astype(str).fillna(\"\").tolist()\n",
        "    print(f\"Извлечено {len(reviews)} отзывов из столбца '{text_column}'.\")\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdL7GIt50iEJ"
      },
      "outputs": [],
      "source": [
        "# обработка отзыва LLM\n",
        "def call_llm_for_review(client, model, review, system_prompt):\n",
        "    \"\"\"\n",
        "    Отправляет один отзыв в LLM и получает ответ.\n",
        "    :param client: OpenAI-совместимый клиент\n",
        "    :param model: Название модели\n",
        "    :param review: Текст отзыва\n",
        "    :param system_prompt: Системный промпт с инструкцией\n",
        "    :return: Сырой строковый ответ от модели\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": f\"Распознай отзыв: {review}\"}\n",
        "            ],\n",
        "            temperature=0.3\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Ошибка при обращении к LLM: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5elYJVJ90iJ4"
      },
      "outputs": [],
      "source": [
        "def clean_and_parse_json(llm_response):\n",
        "    \"\"\"\n",
        "    Очищает ответ LLM от markdown-разметки и парсит как JSON.\n",
        "    Поддерживает случаи: ```json{...}```, `{...}`, с пробелами, переносами и т.п.\n",
        "    :param llm_response: Строка от LLM\n",
        "    :return: Распаршенный словарь или None\n",
        "    \"\"\"\n",
        "    if not llm_response:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Удаляем возможные блоки markdown\n",
        "        cleaned = re.sub(r'^\\s*```(?:json)?|```\\s*$', '', llm_response, flags=re.MULTILINE)\n",
        "        cleaned = cleaned.strip()\n",
        "\n",
        "        # Парсим JSON\n",
        "        parsed = json.loads(cleaned)\n",
        "        return parsed\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ Ошибка парсинга JSON: {e}\")\n",
        "        print(f\"Сырой ответ: {repr(llm_response)}\")\n",
        "        return None\n",
        "\n",
        "def flatten_results(data):\n",
        "    \"\"\"\n",
        "    КОСТЫЛЬ убирает вложенность 'results', поднимая его содержимое на верхний уровень.\n",
        "\n",
        "    Пример:\n",
        "    {\n",
        "      \"review_id\": 1,\n",
        "      \"results\": { \"annotations\": [...] }\n",
        "    }\n",
        "    →\n",
        "    {\n",
        "      \"review_id\": 1,\n",
        "      \"annotations\": [...]\n",
        "    }\n",
        "    \"\"\"\n",
        "    if isinstance(data, list):\n",
        "        return [flatten_results(item) for item in data]\n",
        "    elif isinstance(data, dict):\n",
        "        # Если есть ключ 'results' — распаковываем его\n",
        "        if \"results\" in data and isinstance(data[\"results\"], dict):\n",
        "            # Начинаем с копии ВЕРХНЕГО уровня (включая review_id)\n",
        "            flattened = {k: v for k, v in data.items() if k != \"results\"}\n",
        "            # Добавляем всё из results (перезаписывая только в случае конфликта)\n",
        "            flattened.update(data[\"results\"])\n",
        "            return flattened\n",
        "        else:\n",
        "            # Рекурсивно обрабатываем вложенные структуры\n",
        "            return {k: flatten_results(v) for k, v in data.items()}\n",
        "    else:\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-vmhzr91NyE"
      },
      "outputs": [],
      "source": [
        "# создание результата\n",
        "def build_final_entry(review_id, llm_parsed_response):\n",
        "    \"\"\"\n",
        "    Создаёт один элемент результата.\n",
        "    Берёт содержимое поля 'annotations' из ответа LLM и помещает в results.annotations.\n",
        "\n",
        "    :param review_id: Индекс отзыва (int)\n",
        "    :param llm_parsed_response: Распаршенный словарь от LLM (может быть None)\n",
        "    :return: Словарь в формате {\"review_id\": ..., \"results\": {\"annotations\": [...]}}\n",
        "    \"\"\"\n",
        "    # Если ответа нет — возвращаем пустой массив аннотаций\n",
        "    if not llm_parsed_response:\n",
        "        annotations_list = []\n",
        "    else:\n",
        "        # Извлекаем список из поля 'annotations', если оно есть\n",
        "        if isinstance(llm_parsed_response, dict) and 'annotations' in llm_parsed_response:\n",
        "            annotations_list = llm_parsed_response['annotations']\n",
        "            # Проверяем, что это действительно список\n",
        "            if not isinstance(annotations_list, list):\n",
        "                print(f\"⚠️ Ожидался список в 'annotations', получено: {type(annotations_list)}\")\n",
        "                annotations_list = []\n",
        "        else:\n",
        "            # Если структура другая (например, сразу категория + summary), оборачиваем в список\n",
        "            # Например: {\"category\": \"...\", \"summary\": \"...\"} → превращаем в [{\"category\": \"...\", \"summary\": \"...\"}]\n",
        "            if isinstance(llm_parsed_response, dict):\n",
        "                annotations_list = [{k: v for k, v in llm_parsed_response.items() if k in [\"category\", \"summary\"]}]\n",
        "                # На всякий случай проверим, что есть данные\n",
        "                if not any(annotations_list[0].values()):\n",
        "                    annotations_list = []\n",
        "            else:\n",
        "                annotations_list = []\n",
        "\n",
        "    return {\n",
        "        \"review_id\": review_id,\n",
        "        \"results\": {\n",
        "            \"annotations\": annotations_list\n",
        "        }\n",
        "    }\n",
        "\n",
        "def save_results_to_json(data, output_filename=\"llm_annotations.json\"):\n",
        "    \"\"\"\n",
        "    Сохраняет результат в JSON-файл и предлагает скачать.\n",
        "    :param data: Список словарей\n",
        "    :param output_filename: Имя выходного файла\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"💾 Результат сохранён в '{output_filename}'\")\n",
        "\n",
        "        # Для Colab — возможность скачать\n",
        "        files.download(output_filename)\n",
        "        print(\"📥 Файл доступен для скачивания.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при сохранении: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nygj8V-1N0w"
      },
      "outputs": [],
      "source": [
        "def process_reviews_with_llm(client, model, reviews, system_prompt, batch_size=None):\n",
        "    \"\"\"\n",
        "    Обрабатывает список отзывов через LLM.\n",
        "    :param client: OpenAI-клиент\n",
        "    :param model: Модель\n",
        "    :param reviews: Список текстов отзывов\n",
        "    :param system_prompt: Системный промпт\n",
        "    :param batch_size: Опционально — ограничение на количество отзывов (для теста)\n",
        "    :return: Список финальных словарей\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Ограничиваем размер, если нужно (для тестирования)\n",
        "    if batch_size:\n",
        "        reviews = reviews[:batch_size]\n",
        "        print(f\"Обработка первых {len(reviews)} отзывов (режим теста).\")\n",
        "\n",
        "    total = len(reviews)\n",
        "    print(f\"Начинаем обработку {total} отзывов...\")\n",
        "\n",
        "    for idx, review in enumerate(reviews):\n",
        "        if not review.strip():\n",
        "            print(f\"[{idx}] Пропущен пустой отзыв.\")\n",
        "            entry = build_final_entry(idx, None)\n",
        "            results.append(entry)\n",
        "            continue\n",
        "\n",
        "        print(f\"[{idx + 1}/{total}] Обработка отзыва...\")\n",
        "        raw_response = call_llm_for_review(client, model, review, system_prompt)\n",
        "\n",
        "        if raw_response is None:\n",
        "            print(f\"[{idx}] Ошибка получения ответа от LLM.\")\n",
        "            entry = build_final_entry(idx, None)\n",
        "        else:\n",
        "            parsed = clean_and_parse_json(raw_response)\n",
        "            if parsed is None:\n",
        "                print(f\"[{idx}] Не удалось распарсить ответ. Используется пустая аннотация.\")\n",
        "            entry = build_final_entry(idx, parsed)\n",
        "\n",
        "        results.append(entry)\n",
        "\n",
        "    print(\"✅ Все отзывы обработаны.\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1FG1VvoUKXA"
      },
      "outputs": [],
      "source": [
        "# чекпойнты\n",
        "# def save_checkpoint(data, checkpoint_id):\n",
        "\n",
        "#     filename = f\"checkpoint_{checkpoint_id}.json\"\n",
        "#     with open(filename, 'w', encoding='utf-8') as f:\n",
        "#         json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "#     print(f\"✅ Чекпоинт {checkpoint_id} сохранён в '{filename}'\")\n",
        "#     files.download(filename)\n",
        "\n",
        "def save_checkpoint(data, counter, prefix=\"checkpoint_\"):\n",
        "    \"\"\"\n",
        "    Сохраняет промежуточный результат.\n",
        "    :param data: Список записей\n",
        "    :param checkpoint_id: Номер чекпоинта\n",
        "    \"\"\"\n",
        "    filename = f\"{prefix}{counter}.json\"\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"💾 Чекпоинт сохранён: {filename}\")\n",
        "\n",
        "\n",
        "def merge_checkpoints(output_file=\"final_result.json\"):\n",
        "    \"\"\"\n",
        "    Собирает все checkpoint_*.json в один файл.\n",
        "    :param output_file: Имя финального файла\n",
        "    \"\"\"\n",
        "    import glob\n",
        "\n",
        "    checkpoints = sorted(glob.glob(\"checkpoint_*.json\"))\n",
        "    if not checkpoints:\n",
        "        print(\"❌ Не найдено ни одного чекпоинта.\")\n",
        "        return\n",
        "\n",
        "    final_data = []\n",
        "    for cp in checkpoints:\n",
        "        try:\n",
        "            with open(cp, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                if isinstance(data, list):\n",
        "                    final_data.extend(data)\n",
        "                else:\n",
        "                    print(f\"⚠️ Файл {cp} содержит несписковые данные, пропущено.\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Ошибка чтения {cp}: {e}\")\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"🎯 Все чекпоинты объединены. Итоговый файл: {output_file}\")\n",
        "    files.download(output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMW8uZkZ8GTW",
        "outputId": "b2441d6e-742e-4100-f26f-ba3652f36919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Большие языковые модели, такие как я, умеют выполнять широкий спектр задач, связанных с обработкой и генерацией текста. Вот некоторые из вещей, которые мы умеем делать:\n",
            "\n",
            "1. **Ответы на вопросы**: Мы можем понимать и отвечать на вопросы на различные темы, используя знания, которые мы получили во время обучения.\n",
            "2. **Генерация текста**: Мы можем генерировать текст на основе заданного начала, темы или стиля. Это может быть полезно для написания статей, создания контента или даже генерации кода.\n",
            "3. **Перевод текста**: Мы можем переводить текст с одного языка на другой, используя свои знания о лингвистических структурах и словарном запасе.\n",
            "4. **Суммаризация текста**: Мы можем суммировать длинные тексты, выделяя основные моменты и суть информации.\n",
            "5. **Классификация текста**: Мы можем классифицировать текст по различным категориям, таким как спам/не спам, положительный/отрицательный отзыв и т.д.\n",
            "6. **Разговор**: Мы можем вести разговор с пользователями, отвечая на их вопросы и комментарии в контексте разговора.\n",
            "7. **Создание контента**: Мы можем создавать контент, такой как статьи, посты в социальных сетях, описания продуктов и т.д.\n",
            "8. **Проверка орфографии и грамматики**: Мы можем проверять текст на наличие орфографических и грамматических ошибок и предлагать исправления.\n",
            "9. **Синтез речи**: Мы можем генерировать речь на основе текста, используя свои знания о фонетике и произношении.\n",
            "10. **Игра в языковые игры**: Мы можем играть в языковые игры, такие как \"виселица\", \"анаграммы\" и т.д.\n",
            "\n",
            "Это лишь небольшой пример того, что мы умеем делать. Большие языковые модели, такие как я, постоянно развиваются и совершенствуются, поэтому наш потенциал еще не полностью раскрыт.\n"
          ]
        }
      ],
      "source": [
        "# создание llm клиента\n",
        "import openai\n",
        "client = openai.OpenAI(\n",
        "    api_key=YANDEX_CLOUD_API_KEY,\n",
        "    base_url=\"https://llm.api.cloud.yandex.net/v1\"\n",
        ")\n",
        "model_name = \"llama\"\n",
        "model=f\"gpt://{YANDEX_CLOUD_FOLDER}/{model_name}/latest\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Ты очень умный ассистент.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Что умеют большие языковые модели?\"}\n",
        "    ],\n",
        "    temperature=0.3\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ЗАГРУЗКА / ИНИЦИАЛИЗАЦИЯ КАТЕГОРИЙ ===\n",
        "def load_categories():\n",
        "    if os.path.exists(CATEGORIES_FILE):\n",
        "        with open(CATEGORIES_FILE, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    else:\n",
        "        print(\"📁 Создаём начальный список категорий...\")\n",
        "        save_categories(DEFAULT_CATEGORIES)\n",
        "        return DEFAULT_CATEGORIES.copy()\n",
        "\n",
        "def save_categories(categories):\n",
        "    with open(CATEGORIES_FILE, 'w', encoding='utf-8') as f:\n",
        "        json.dump(sorted(list(set(categories))), f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "-yUBJzs93q24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === НАСТРОЙКИ (с чекпойнтами, адаптивность выключена) ===\n",
        "TEXT_COLUMN = \"review_text\"\n",
        "\n",
        "MAX_BATCH = 180\n",
        "SELECTION_LEN = 300\n",
        "CATEGORIES_FILE = \"current_categories.json\"  # Файл для хранения списка категорий\n",
        "CHECKPOINT_DIR = \"checkpoints\"\n",
        "\n",
        "# Инициализация начальных категорий\n",
        "DEFAULT_CATEGORIES = [\n",
        "    \"Карты\",\n",
        "    \"Банкоматы\",\n",
        "    \"Кэшбэк / Бонусы\",\n",
        "    \"Обслуживание в офисе\",\n",
        "    \"Вклады\",\n",
        "    \"Кредиты\",\n",
        "    \"Курьерская служба\",\n",
        "    \"Приложение / сайт\",\n",
        "    \"Служба поддержки\",\n",
        "    \"Счета\",\n",
        "    \"Прочие услуги\"\n",
        "]\n",
        "SENTIMENTS = [\n",
        "   \"позитив\", \"негатив\", \"нейтральный\"\n",
        "]\n",
        "\n",
        "\n",
        "# === ПРОМПТ СО СТАТИЧНЫМИ ===\n",
        "def build_system_prompt(allowed_categories):\n",
        "    categories_list = ', '.join([f'\"{cat}\"' for cat in allowed_categories])\n",
        "    return f\"\"\"\n",
        "Проанализируй отзыв клиента банка и определи, какие продукты или услуги упоминаются, а также тональность отзыва (позитив/негатив/нейтральный)\n",
        "\n",
        "Правила:\n",
        "1. Категория должна быть ТОЛЬКО из следующего списка: {categories_list} . Запрещено выдумывать новые.\n",
        "Запрещено добавлять категории, если они не упоминаются в отзыве\n",
        "Дополнительное правило для определения категорий взаимодействия с клиентом\n",
        "**признаки обслуживания в офисе**\n",
        "- упоминания что КЛИЕНТ пришел, приехал в банк, в отделение, в офис\n",
        "**признаки курьерской службы**\n",
        "- упоминание что ПРЕДСТАВИТЕЛЬ БАНКА пришел, приехал к клиенту, а не наоборот. упоминание назначения времени и места встречи\n",
        "**признаки службы поддержки**\n",
        "- упоминание что клиент звонил, писал в чат, на сайт, общался с ботом\n",
        "\n",
        "2. Категория \"Прочие услуги\" применяется ТОЛЬКО если ни одна из прочих категорий не подходит.\n",
        "  Общие формулировки вроде \"отличный банк\"/\"ужасный банк\" без указания обстоятельств не классифицируем.\n",
        "3. Тональность должна иметь ТОЛЬКО одно из трех значений: позитив, негатив или нейтральный.\n",
        "  Если по одной категории найдено несколько смысловых фрагментов, то категория не повторяется, а сентименты складываются\n",
        "  Например, \"условия по картам хорошие, но цифры с пластика быстро стираются\". -1 +1 = 0 -> \"нейтрально\"\n",
        "4. Саммари должно содержать аспект и отношение к нему клиента. Например \"клиент не смог восстановить доступ к заблокированному счету\"\n",
        "  Не делай саммари вроде \"Отзыв о карте Газпромбанка\" - это не информативно.\n",
        "\n",
        "\n",
        "Формат ответа:\n",
        "\n",
        "  {{ \"annotations\": [{{\"category\": \"...\", \"summary\": \"...\", \"sentiment\": \"...\" }}, ...] }}\n",
        "\n",
        "Ответ должен быть ТОЛЬКО валидным JSON.\n",
        "\"\"\"\n",
        "\n",
        "# === ОБРАБОТКА ОТЗЫВА ЧЕРЕЗ LLM ===\n",
        "def call_llm_with_categories(client, model, review, categories):\n",
        "    prompt = build_system_prompt(categories)\n",
        "    raw_response = call_llm_for_review(client, model, review, prompt)\n",
        "    return clean_and_parse_json(raw_response) if raw_response else None\n",
        "\n",
        "# === ВЫПОЛНЕНИЕ ===\n",
        "try:\n",
        "    # 0. Загружаем файл\n",
        "    filepath = upload_csv()\n",
        "\n",
        "    # 1. Читаем CSV\n",
        "    df = load_csv_to_dataframe(filepath)\n",
        "\n",
        "\n",
        "    # 2. Извлекаем отзывы\n",
        "    reviews = extract_reviews(df, text_column=TEXT_COLUMN)\n",
        "    total_reviews = len(reviews)\n",
        "    print(f\"📊 Всего отзывов для обработки: {total_reviews}\")\n",
        "\n",
        "    if total_reviews == 0:\n",
        "        raise ValueError(\"Список отзывов пуст. Проверьте название столбца.\")\n",
        "\n",
        "    # 3. Загружаем текущие категории\n",
        "    current_categories = load_categories()\n",
        "    print(f\"🏷️  Текущие категории ({len(current_categories)}): {current_categories}\")\n",
        "\n",
        "    # 4. Обработка порциями\n",
        "    all_results = []\n",
        "    checkpoint_counter = 0\n",
        "\n",
        "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "    for i in range(0, total_reviews, MAX_BATCH):\n",
        "        batch = reviews[i:i + MAX_BATCH]\n",
        "        batch_results = []\n",
        "\n",
        "        print(f\"\\n--- Обработка батча {i//MAX_BATCH + 1} ({i}–{min(i + MAX_BATCH, total_reviews)}) ---\")\n",
        "        print(f\"📌 Используется {len(current_categories)} категорий\")\n",
        "\n",
        "        new_categories_in_batch = []  # собираем новые категории из этого батча\n",
        "\n",
        "        for idx_in_batch, review in enumerate(batch):\n",
        "            global_idx = i + idx_in_batch\n",
        "\n",
        "            print(f\"[{global_idx + 1}/{total_reviews}] Обработка отзыва...\")\n",
        "            response = call_llm_with_categories(client, model, review, current_categories)\n",
        "\n",
        "            if not response:\n",
        "                entry = build_final_entry(global_idx, None)\n",
        "                batch_results.append(entry)\n",
        "                continue\n",
        "\n",
        "            # Проверяем, есть ли новая категория\n",
        "            if \"new_category\" in response:\n",
        "                new_cat = response[\"new_category\"].strip()\n",
        "                if new_cat and new_cat not in current_categories and new_cat not in new_categories_in_batch:\n",
        "                    new_categories_in_batch.append(new_cat)\n",
        "                    print(f\"✨ Новая категория: '{new_cat}'\")\n",
        "\n",
        "                # Удаляем new_category из финального вывода\n",
        "                response.pop(\"new_category\", None)\n",
        "\n",
        "            entry = build_final_entry(global_idx, response)\n",
        "            batch_results.append(entry)\n",
        "\n",
        "        # После обработки батча — обновляем глобальный список категорий\n",
        "        if new_categories_in_batch:\n",
        "            current_categories.extend(new_categories_in_batch)\n",
        "            current_categories = sorted(list(set(current_categories)))  # dedup\n",
        "            save_categories(current_categories)\n",
        "            print(f\"✅ Добавлено новых категорий: {len(new_categories_in_batch)}. Всего категорий: {len(current_categories)}\")\n",
        "\n",
        "        # Сохраняем результаты батча\n",
        "        all_results.extend(batch_results)\n",
        "        save_checkpoint(batch_results, checkpoint_counter, prefix=\"batch_\")\n",
        "        checkpoint_counter += 1\n",
        "\n",
        "    # 5. Финальное сохранение\n",
        "    #all_results_flat = flatten_results(all_results)   #убираем лишний ключ 'results'\n",
        "    final_filename = \"llm_annotations_full.json\"\n",
        "    with open(final_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"🎉 Обработка завершена! Сохранено {len(all_results)} записей.\")\n",
        "    print(f\"📌 Итоговое количество категорий: {len(current_categories)}\")\n",
        "    files.download(final_filename)\n",
        "    files.download(CATEGORIES_FILE)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"🚨 Ошибка: {e}\")\n",
        "    print(\"💡 Совет: используйте merge_checkpoints(), чтобы восстановить данные.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NTmCBE9FsiO3",
        "outputId": "1c267020-83d6-474b-f6d3-7bb653edaa9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузите CSV-файл...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-27b10292-6e3d-4db7-83da-f8e72c444639\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-27b10292-6e3d-4db7-83da-f8e72c444639\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_for_mark_330.csv to data_for_mark_330.csv\n",
            "Файл 'data_for_mark_330.csv' успешно загружен.\n",
            "Файл успешно прочитан. Размер: (330, 3)\n",
            "Извлечено 330 отзывов из столбца 'review_text'.\n",
            "📊 Всего отзывов для обработки: 330\n",
            "📁 Создаём начальный список категорий...\n",
            "🏷️  Текущие категории (11): ['Карты', 'Банкоматы', 'Кэшбэк / Бонусы', 'Обслуживание в офисе', 'Вклады', 'Кредиты', 'Курьерская служба', 'Приложение / сайт', 'Служба поддержки', 'Счета', 'Прочие услуги']\n",
            "\n",
            "--- Обработка батча 1 (0–180) ---\n",
            "📌 Используется 11 категорий\n",
            "[1/330] Обработка отзыва...\n",
            "[2/330] Обработка отзыва...\n",
            "[3/330] Обработка отзыва...\n",
            "[4/330] Обработка отзыва...\n",
            "[5/330] Обработка отзыва...\n",
            "[6/330] Обработка отзыва...\n",
            "[7/330] Обработка отзыва...\n",
            "[8/330] Обработка отзыва...\n",
            "[9/330] Обработка отзыва...\n",
            "[10/330] Обработка отзыва...\n",
            "[11/330] Обработка отзыва...\n",
            "[12/330] Обработка отзыва...\n",
            "[13/330] Обработка отзыва...\n",
            "[14/330] Обработка отзыва...\n",
            "[15/330] Обработка отзыва...\n",
            "[16/330] Обработка отзыва...\n",
            "[17/330] Обработка отзыва...\n",
            "[18/330] Обработка отзыва...\n",
            "[19/330] Обработка отзыва...\n",
            "[20/330] Обработка отзыва...\n",
            "[21/330] Обработка отзыва...\n",
            "[22/330] Обработка отзыва...\n",
            "[23/330] Обработка отзыва...\n",
            "[24/330] Обработка отзыва...\n",
            "[25/330] Обработка отзыва...\n",
            "[26/330] Обработка отзыва...\n",
            "[27/330] Обработка отзыва...\n",
            "[28/330] Обработка отзыва...\n",
            "[29/330] Обработка отзыва...\n",
            "[30/330] Обработка отзыва...\n",
            "[31/330] Обработка отзыва...\n",
            "[32/330] Обработка отзыва...\n",
            "[33/330] Обработка отзыва...\n",
            "[34/330] Обработка отзыва...\n",
            "[35/330] Обработка отзыва...\n",
            "[36/330] Обработка отзыва...\n",
            "[37/330] Обработка отзыва...\n",
            "[38/330] Обработка отзыва...\n",
            "[39/330] Обработка отзыва...\n",
            "[40/330] Обработка отзыва...\n",
            "[41/330] Обработка отзыва...\n",
            "[42/330] Обработка отзыва...\n",
            "[43/330] Обработка отзыва...\n",
            "[44/330] Обработка отзыва...\n",
            "[45/330] Обработка отзыва...\n",
            "[46/330] Обработка отзыва...\n",
            "[47/330] Обработка отзыва...\n",
            "[48/330] Обработка отзыва...\n",
            "[49/330] Обработка отзыва...\n",
            "[50/330] Обработка отзыва...\n",
            "[51/330] Обработка отзыва...\n",
            "[52/330] Обработка отзыва...\n",
            "[53/330] Обработка отзыва...\n",
            "[54/330] Обработка отзыва...\n",
            "[55/330] Обработка отзыва...\n",
            "[56/330] Обработка отзыва...\n",
            "[57/330] Обработка отзыва...\n",
            "[58/330] Обработка отзыва...\n",
            "[59/330] Обработка отзыва...\n",
            "[60/330] Обработка отзыва...\n",
            "[61/330] Обработка отзыва...\n",
            "[62/330] Обработка отзыва...\n",
            "[63/330] Обработка отзыва...\n",
            "[64/330] Обработка отзыва...\n",
            "[65/330] Обработка отзыва...\n",
            "[66/330] Обработка отзыва...\n",
            "[67/330] Обработка отзыва...\n",
            "[68/330] Обработка отзыва...\n",
            "[69/330] Обработка отзыва...\n",
            "[70/330] Обработка отзыва...\n",
            "[71/330] Обработка отзыва...\n",
            "[72/330] Обработка отзыва...\n",
            "[73/330] Обработка отзыва...\n",
            "[74/330] Обработка отзыва...\n",
            "[75/330] Обработка отзыва...\n",
            "[76/330] Обработка отзыва...\n",
            "[77/330] Обработка отзыва...\n",
            "[78/330] Обработка отзыва...\n",
            "[79/330] Обработка отзыва...\n",
            "[80/330] Обработка отзыва...\n",
            "[81/330] Обработка отзыва...\n",
            "[82/330] Обработка отзыва...\n",
            "[83/330] Обработка отзыва...\n",
            "[84/330] Обработка отзыва...\n",
            "[85/330] Обработка отзыва...\n",
            "[86/330] Обработка отзыва...\n",
            "[87/330] Обработка отзыва...\n",
            "[88/330] Обработка отзыва...\n",
            "❌ Ошибка парсинга JSON: Expecting value: line 1 column 1 (char 0)\n",
            "Сырой ответ: 'Я не могу обсуждать эту тему. Давайте поговорим о чём-нибудь ещё.'\n",
            "[89/330] Обработка отзыва...\n",
            "[90/330] Обработка отзыва...\n",
            "[91/330] Обработка отзыва...\n",
            "[92/330] Обработка отзыва...\n",
            "[93/330] Обработка отзыва...\n",
            "[94/330] Обработка отзыва...\n",
            "[95/330] Обработка отзыва...\n",
            "[96/330] Обработка отзыва...\n",
            "[97/330] Обработка отзыва...\n",
            "[98/330] Обработка отзыва...\n",
            "[99/330] Обработка отзыва...\n",
            "[100/330] Обработка отзыва...\n",
            "[101/330] Обработка отзыва...\n",
            "[102/330] Обработка отзыва...\n",
            "[103/330] Обработка отзыва...\n",
            "[104/330] Обработка отзыва...\n",
            "[105/330] Обработка отзыва...\n",
            "[106/330] Обработка отзыва...\n",
            "[107/330] Обработка отзыва...\n",
            "[108/330] Обработка отзыва...\n",
            "[109/330] Обработка отзыва...\n",
            "[110/330] Обработка отзыва...\n",
            "[111/330] Обработка отзыва...\n",
            "[112/330] Обработка отзыва...\n",
            "[113/330] Обработка отзыва...\n",
            "[114/330] Обработка отзыва...\n",
            "[115/330] Обработка отзыва...\n",
            "[116/330] Обработка отзыва...\n",
            "[117/330] Обработка отзыва...\n",
            "[118/330] Обработка отзыва...\n",
            "[119/330] Обработка отзыва...\n",
            "[120/330] Обработка отзыва...\n",
            "[121/330] Обработка отзыва...\n",
            "[122/330] Обработка отзыва...\n",
            "[123/330] Обработка отзыва...\n",
            "[124/330] Обработка отзыва...\n",
            "[125/330] Обработка отзыва...\n",
            "[126/330] Обработка отзыва...\n",
            "[127/330] Обработка отзыва...\n",
            "[128/330] Обработка отзыва...\n",
            "[129/330] Обработка отзыва...\n",
            "[130/330] Обработка отзыва...\n",
            "[131/330] Обработка отзыва...\n",
            "[132/330] Обработка отзыва...\n",
            "[133/330] Обработка отзыва...\n",
            "[134/330] Обработка отзыва...\n",
            "[135/330] Обработка отзыва...\n",
            "[136/330] Обработка отзыва...\n",
            "[137/330] Обработка отзыва...\n",
            "[138/330] Обработка отзыва...\n",
            "[139/330] Обработка отзыва...\n",
            "[140/330] Обработка отзыва...\n",
            "[141/330] Обработка отзыва...\n",
            "[142/330] Обработка отзыва...\n",
            "[143/330] Обработка отзыва...\n",
            "[144/330] Обработка отзыва...\n",
            "[145/330] Обработка отзыва...\n",
            "[146/330] Обработка отзыва...\n",
            "[147/330] Обработка отзыва...\n",
            "[148/330] Обработка отзыва...\n",
            "[149/330] Обработка отзыва...\n",
            "[150/330] Обработка отзыва...\n",
            "[151/330] Обработка отзыва...\n",
            "[152/330] Обработка отзыва...\n",
            "[153/330] Обработка отзыва...\n",
            "[154/330] Обработка отзыва...\n",
            "[155/330] Обработка отзыва...\n",
            "[156/330] Обработка отзыва...\n",
            "[157/330] Обработка отзыва...\n",
            "[158/330] Обработка отзыва...\n",
            "[159/330] Обработка отзыва...\n",
            "[160/330] Обработка отзыва...\n",
            "[161/330] Обработка отзыва...\n",
            "[162/330] Обработка отзыва...\n",
            "[163/330] Обработка отзыва...\n",
            "[164/330] Обработка отзыва...\n",
            "[165/330] Обработка отзыва...\n",
            "[166/330] Обработка отзыва...\n",
            "[167/330] Обработка отзыва...\n",
            "[168/330] Обработка отзыва...\n",
            "[169/330] Обработка отзыва...\n",
            "[170/330] Обработка отзыва...\n",
            "[171/330] Обработка отзыва...\n",
            "[172/330] Обработка отзыва...\n",
            "[173/330] Обработка отзыва...\n",
            "[174/330] Обработка отзыва...\n",
            "[175/330] Обработка отзыва...\n",
            "[176/330] Обработка отзыва...\n",
            "[177/330] Обработка отзыва...\n",
            "[178/330] Обработка отзыва...\n",
            "[179/330] Обработка отзыва...\n",
            "[180/330] Обработка отзыва...\n",
            "💾 Чекпоинт сохранён: batch_0.json\n",
            "\n",
            "--- Обработка батча 2 (180–330) ---\n",
            "📌 Используется 11 категорий\n",
            "[181/330] Обработка отзыва...\n",
            "[182/330] Обработка отзыва...\n",
            "[183/330] Обработка отзыва...\n",
            "[184/330] Обработка отзыва...\n",
            "[185/330] Обработка отзыва...\n",
            "[186/330] Обработка отзыва...\n",
            "[187/330] Обработка отзыва...\n",
            "[188/330] Обработка отзыва...\n",
            "[189/330] Обработка отзыва...\n",
            "[190/330] Обработка отзыва...\n",
            "[191/330] Обработка отзыва...\n",
            "[192/330] Обработка отзыва...\n",
            "[193/330] Обработка отзыва...\n",
            "[194/330] Обработка отзыва...\n",
            "[195/330] Обработка отзыва...\n",
            "[196/330] Обработка отзыва...\n",
            "[197/330] Обработка отзыва...\n",
            "[198/330] Обработка отзыва...\n",
            "[199/330] Обработка отзыва...\n",
            "[200/330] Обработка отзыва...\n",
            "[201/330] Обработка отзыва...\n",
            "[202/330] Обработка отзыва...\n",
            "[203/330] Обработка отзыва...\n",
            "❌ Ошибка парсинга JSON: Expecting value: line 1 column 1 (char 0)\n",
            "Сырой ответ: 'Я не могу обсуждать эту тему. Давайте поговорим о чём-нибудь ещё.'\n",
            "[204/330] Обработка отзыва...\n",
            "[205/330] Обработка отзыва...\n",
            "[206/330] Обработка отзыва...\n",
            "[207/330] Обработка отзыва...\n",
            "[208/330] Обработка отзыва...\n",
            "[209/330] Обработка отзыва...\n",
            "[210/330] Обработка отзыва...\n",
            "[211/330] Обработка отзыва...\n",
            "[212/330] Обработка отзыва...\n",
            "[213/330] Обработка отзыва...\n",
            "[214/330] Обработка отзыва...\n",
            "[215/330] Обработка отзыва...\n",
            "[216/330] Обработка отзыва...\n",
            "[217/330] Обработка отзыва...\n",
            "[218/330] Обработка отзыва...\n",
            "[219/330] Обработка отзыва...\n",
            "[220/330] Обработка отзыва...\n",
            "[221/330] Обработка отзыва...\n",
            "[222/330] Обработка отзыва...\n",
            "[223/330] Обработка отзыва...\n",
            "[224/330] Обработка отзыва...\n",
            "[225/330] Обработка отзыва...\n",
            "[226/330] Обработка отзыва...\n",
            "❌ Ошибка парсинга JSON: Expecting value: line 1 column 1 (char 0)\n",
            "Сырой ответ: 'Я не могу обсуждать эту тему. Давайте поговорим о чём-нибудь ещё.'\n",
            "[227/330] Обработка отзыва...\n",
            "[228/330] Обработка отзыва...\n",
            "[229/330] Обработка отзыва...\n",
            "[230/330] Обработка отзыва...\n",
            "[231/330] Обработка отзыва...\n",
            "[232/330] Обработка отзыва...\n",
            "[233/330] Обработка отзыва...\n",
            "[234/330] Обработка отзыва...\n",
            "[235/330] Обработка отзыва...\n",
            "[236/330] Обработка отзыва...\n",
            "[237/330] Обработка отзыва...\n",
            "[238/330] Обработка отзыва...\n",
            "[239/330] Обработка отзыва...\n",
            "[240/330] Обработка отзыва...\n",
            "[241/330] Обработка отзыва...\n",
            "[242/330] Обработка отзыва...\n",
            "[243/330] Обработка отзыва...\n",
            "[244/330] Обработка отзыва...\n",
            "[245/330] Обработка отзыва...\n",
            "[246/330] Обработка отзыва...\n",
            "[247/330] Обработка отзыва...\n",
            "[248/330] Обработка отзыва...\n",
            "[249/330] Обработка отзыва...\n",
            "[250/330] Обработка отзыва...\n",
            "[251/330] Обработка отзыва...\n",
            "[252/330] Обработка отзыва...\n",
            "[253/330] Обработка отзыва...\n",
            "[254/330] Обработка отзыва...\n",
            "[255/330] Обработка отзыва...\n",
            "[256/330] Обработка отзыва...\n",
            "[257/330] Обработка отзыва...\n",
            "[258/330] Обработка отзыва...\n",
            "[259/330] Обработка отзыва...\n",
            "[260/330] Обработка отзыва...\n",
            "[261/330] Обработка отзыва...\n",
            "[262/330] Обработка отзыва...\n",
            "[263/330] Обработка отзыва...\n",
            "[264/330] Обработка отзыва...\n",
            "[265/330] Обработка отзыва...\n",
            "[266/330] Обработка отзыва...\n",
            "[267/330] Обработка отзыва...\n",
            "[268/330] Обработка отзыва...\n",
            "[269/330] Обработка отзыва...\n",
            "[270/330] Обработка отзыва...\n",
            "[271/330] Обработка отзыва...\n",
            "[272/330] Обработка отзыва...\n",
            "[273/330] Обработка отзыва...\n",
            "[274/330] Обработка отзыва...\n",
            "[275/330] Обработка отзыва...\n",
            "[276/330] Обработка отзыва...\n",
            "[277/330] Обработка отзыва...\n",
            "[278/330] Обработка отзыва...\n",
            "[279/330] Обработка отзыва...\n",
            "[280/330] Обработка отзыва...\n",
            "[281/330] Обработка отзыва...\n",
            "[282/330] Обработка отзыва...\n",
            "[283/330] Обработка отзыва...\n",
            "[284/330] Обработка отзыва...\n",
            "[285/330] Обработка отзыва...\n",
            "[286/330] Обработка отзыва...\n",
            "[287/330] Обработка отзыва...\n",
            "[288/330] Обработка отзыва...\n",
            "[289/330] Обработка отзыва...\n",
            "[290/330] Обработка отзыва...\n",
            "[291/330] Обработка отзыва...\n",
            "[292/330] Обработка отзыва...\n",
            "[293/330] Обработка отзыва...\n",
            "[294/330] Обработка отзыва...\n",
            "[295/330] Обработка отзыва...\n",
            "[296/330] Обработка отзыва...\n",
            "[297/330] Обработка отзыва...\n",
            "[298/330] Обработка отзыва...\n",
            "[299/330] Обработка отзыва...\n",
            "[300/330] Обработка отзыва...\n",
            "[301/330] Обработка отзыва...\n",
            "[302/330] Обработка отзыва...\n",
            "[303/330] Обработка отзыва...\n",
            "[304/330] Обработка отзыва...\n",
            "[305/330] Обработка отзыва...\n",
            "[306/330] Обработка отзыва...\n",
            "[307/330] Обработка отзыва...\n",
            "[308/330] Обработка отзыва...\n",
            "[309/330] Обработка отзыва...\n",
            "[310/330] Обработка отзыва...\n",
            "[311/330] Обработка отзыва...\n",
            "[312/330] Обработка отзыва...\n",
            "[313/330] Обработка отзыва...\n",
            "[314/330] Обработка отзыва...\n",
            "[315/330] Обработка отзыва...\n",
            "[316/330] Обработка отзыва...\n",
            "[317/330] Обработка отзыва...\n",
            "[318/330] Обработка отзыва...\n",
            "[319/330] Обработка отзыва...\n",
            "[320/330] Обработка отзыва...\n",
            "[321/330] Обработка отзыва...\n",
            "[322/330] Обработка отзыва...\n",
            "[323/330] Обработка отзыва...\n",
            "[324/330] Обработка отзыва...\n",
            "[325/330] Обработка отзыва...\n",
            "[326/330] Обработка отзыва...\n",
            "[327/330] Обработка отзыва...\n",
            "[328/330] Обработка отзыва...\n",
            "[329/330] Обработка отзыва...\n",
            "[330/330] Обработка отзыва...\n",
            "💾 Чекпоинт сохранён: batch_1.json\n",
            "🎉 Обработка завершена! Сохранено 330 записей.\n",
            "📌 Итоговое количество категорий: 11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_30b1b87d-12cd-481b-968c-912e1b875c59\", \"llm_annotations_full.json\", 254101)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_81cd0ded-a28b-44db-b0f0-cdbff2162766\", \"current_categories.json\", 317)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузить финальный результат\n",
        "import json\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Загружаем результаты\n",
        "with open('llm_annotations_full.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "iRHMyXR6Xymd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# извлечение категорий\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "categories = []\n",
        "for item in data:\n",
        "\n",
        "    annotations = item[\"results\"].get(\"annotations\", [])\n",
        "    for ann in annotations:\n",
        "        cat = ann.get(\"category\", \"\").strip()\n",
        "        if cat:\n",
        "            categories.append(cat)\n",
        "\n",
        "print(f\"✅ Найдено упоминаний: {len(categories)}\")\n",
        "print(f\"📌 Уникальных категорий: {len(set(categories))}\")\n",
        "category_counts = Counter(categories)\n",
        "\n",
        "# Превращаем в обычный словарь (если нужно)\n",
        "category_dict = dict(category_counts)\n",
        "\n",
        "# Создаём DataFrame\n",
        "df_counts = pd.DataFrame(list(category_counts.items()), columns=['category', 'count'])\n",
        "\n",
        "# Сортируем по убыванию частоты\n",
        "df_counts = df_counts.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLJ44ribYFFM",
        "outputId": "16dfb789-d09f-45fb-ae17-5800df52592d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Найдено упоминаний: 847\n",
            "📌 Уникальных категорий: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_counts.to_csv('category_frequency.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"💾 Таблица сохранена: category_frequency.csv\")\n",
        "files.download('category_frequency.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qqGkdBNZYOFi",
        "outputId": "0b53976b-977c-4e56-a458-36b7da894216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Таблица сохранена: category_frequency.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab3c134c-ffa1-4a1a-8f3e-1a1047862c0f\", \"category_frequency.csv\", 345)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# дополняем исходный файл категориями и саммари\n",
        "df = load_csv_to_dataframe(filepath)\n",
        "\n",
        "# Загружаем результаты LLM\n",
        "with open('llm_annotations_full.json', 'r', encoding='utf-8') as f:\n",
        "    annotations_data = json.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBf3GsXnexKo",
        "outputId": "a4b390e6-1124-4831-fed0-4b18a7367e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно прочитан. Размер: (330, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим список для новых данных\n",
        "expanded_rows = []\n",
        "\n",
        "for item in annotations_data:\n",
        "    review_id = item[\"review_id\"]\n",
        "    annotations = item[\"results\"].get(\"annotations\", [])\n",
        "\n",
        "    # Если аннотаций нет — всё равно создаём строку с пустыми значениями\n",
        "    if not annotations:\n",
        "        expanded_rows.append({\n",
        "            \"review_id\": review_id,\n",
        "            \"category\": None,\n",
        "            \"summary\": None\n",
        "        })\n",
        "    else:\n",
        "        for ann in annotations:\n",
        "            expanded_rows.append({\n",
        "                \"review_id\": review_id,\n",
        "                \"category\": ann[\"category\"],\n",
        "                \"summary\": ann[\"summary\"]\n",
        "            })\n",
        "\n",
        "# Создаём DataFrame с аннотациями\n",
        "df_annotations = pd.DataFrame(expanded_rows)"
      ],
      "metadata": {
        "id": "3JAOLBine83l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Убедимся, что df имеет правильный индекс\n",
        "df_reset = df.reset_index(drop=True)  # теперь индекс: 0, 1, 2, ..., N-1\n",
        "\n",
        "# === ВАРИАНТ 1: ОДНА СТРОКА НА ОТЗЫВ, списки категорий и саммари ===\n",
        "grouped = df_annotations.groupby('review_id').agg(\n",
        "    extracted_categories=('category', list),\n",
        "    extracted_summaries=('summary', list)\n",
        ")\n",
        "# Оставляем review_id как индекс\n",
        "\n",
        "# Присоединяем по индексу: review_id == индексу df_reset\n",
        "df_enriched = df_reset.join(grouped, how='left')\n",
        "\n",
        "# Заполняем NaN пустыми списками\n",
        "df_enriched['extracted_categories'] = df_enriched['extracted_categories'].apply(lambda x: x if isinstance(x, list) else [])\n",
        "df_enriched['extracted_summaries'] = df_enriched['extracted_summaries'].apply(lambda x: x if isinstance(x, list) else [])"
      ],
      "metadata": {
        "id": "vyx1w2yuexR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраняем результаты\n",
        "output_filename = \"enriched_bank_reviews.csv\"\n",
        "df_enriched.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "print(f\"✅ Обогащённый CSV сохранён: {output_filename}\")\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TV1H-G24fKmj",
        "outputId": "eb974b54-e2e7-4b8b-a792-608756ac6aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Обогащённый CSV сохранён: enriched_bank_reviews.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_994c47da-c5bb-41f8-b576-9c927866df8b\", \"enriched_bank_reviews.csv\", 450005)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем аннотации\n",
        "with open('llm_annotations_full.json', 'r', encoding='utf-8') as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "# Исходный DataFrame (уже загружен ранее)\n",
        "# df — должен быть без изменений порядка строк\n",
        "df_reset = df.reset_index(drop=True)  # гарантируем обычный индекс 0,1,2..."
      ],
      "metadata": {
        "id": "mQcntAyd0Gnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Колонки, которые хочешь добавить к аннотациям\n",
        "COLUMNS_TO_INCLUDE = [TEXT_COLUMN, 'review_dttm', 'review_text']  # например\n",
        "\n",
        "# Проверим, есть ли нужные колонки\n",
        "available_cols = [col for col in COLUMNS_TO_INCLUDE if col in df_reset.columns]\n",
        "if not available_cols:\n",
        "    print(\"⚠️  Нет нужных колонок. Добавим только текст.\")\n",
        "    available_cols = [TEXT_COLUMN] if TEXT_COLUMN in df_reset.columns else []\n",
        "\n",
        "# Преобразуем df в словарь по индексу\n",
        "metadata_dict = df_reset[available_cols].to_dict('index')  # {0: {...}, 1: {...}, ...}\n",
        "\n",
        "# Обновляем аннотации\n",
        "enriched_annotations = []\n",
        "\n",
        "for item in annotations:\n",
        "    review_id = item[\"review_id\"]\n",
        "\n",
        "    # Проверяем, что такой ID существует\n",
        "    if review_id >= len(df_reset):\n",
        "        print(f\"⚠️  Пропущено: review_id={review_id} вне диапазона (всего {len(df_reset)} строк)\")\n",
        "        continue\n",
        "\n",
        "    # Достаём данные из df\n",
        "    row_data = metadata_dict.get(review_id, {})\n",
        "\n",
        "    # Формируем обогащённую запись\n",
        "    enriched_item = {\n",
        "        \"review_id\": review_id,\n",
        "    }\n",
        "\n",
        "    # Добавляем выбранные колонки\n",
        "    for col in available_cols:\n",
        "        value = row_data.get(col, None)\n",
        "        # Приводим к простым типам (на всякий случай)\n",
        "        enriched_item[col] = str(value) if pd.isna(value) else value\n",
        "\n",
        "    # Добавляем результаты LLM\n",
        "    enriched_item[\"results\"] = item.get(\"results\", {})\n",
        "\n",
        "    enriched_annotations.append(enriched_item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asySC4TcyuKK",
        "outputId": "89de69fc-a5fc-42d1-f5ca-036525d15e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3155780198.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
            "  metadata_dict = df_reset[available_cols].to_dict('index')  # {0: {...}, 1: {...}, ...}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename = \"llm_annotations_enriched.json\"\n",
        "\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    json.dump(enriched_annotations, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Обогащённый JSON сохранён: {output_filename}\")\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "98wR20uEyuTd",
        "outputId": "42b92883-39a2-4b68-8a9c-7b0dc856fef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Обогащённый JSON сохранён: llm_annotations_enriched.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2cf6e60b-2513-4a11-adbd-44a58120d5f4\", \"llm_annotations_enriched.json\", 577099)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}