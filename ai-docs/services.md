# Сервисы проекта

Этот документ описывает ключевые сервисы, используемые в проекте `senana/langchain` для взаимодействия с LLM. Сервисы спроектированы для обеспечения модульности и четкого разделения ответственности.

## Обзор архитектуры сервисов

Система состоит из нескольких взаимосвязанных сервисов, которые управляют конфигурацией, реестром моделей, их загрузкой и настройкой.

-   **Сервис конфигурации**: Централизованное управление настройками.
-   **Сервис реестра моделей**: Учет и отслеживание всех LLM моделей.
-   **Сервис загрузки моделей**: Взаимодействие с Ollama и создание экземпляров моделей.
-   **Сервис конфигуратора моделей**: Динамическая настройка параметров моделей.

---

## 1. Сервис конфигурации

Сервис предоставляет централизованный доступ к конфигурационным файлам проекта.

-   **Назначение**: Загрузка, кэширование и предоставление доступа к параметрам из YAML-файлов, в первую очередь `llm_config.yml`.
-   **Ключевые компоненты**:
    -   `ConfigLoader` (`src/utils/config_loader.py`): Утилита для поиска и загрузки YAML-файлов.
    -   `ConfigManager` (`src/utils/config_manager.py`): Singleton для централизованного доступа к настройкам.

### Бизнес-логика

-   `ConfigLoader` использует несколько стратегий для поиска файла конфигурации в структуре проекта.
-   `ConfigManager` загружает конфигурацию один раз и кэширует ее, чтобы избежать повторных чтений файла. Он предоставляет методы для получения как всего файла конфигурации, так и отдельных значений по ключу (включая вложенные).

### Использование

`ConfigManager` является singleton, поэтому его экземпляр получается стандартным вызовом конструктора.

```python
from senana.langchain.src.utils.config_manager import ConfigManager

# Получение экземпляра
config_manager = ConfigManager()

# Получение URL сервера Ollama
ollama_url = config_manager.get_ollama_base_url()

# Получение параметра модели
temp = config_manager.get_model_param("gpt-oss:20b", "temperature", default=0.7)
```

-   **Входные данные**: `llm_config.yml` и другие YAML-файлы.
-   **Выходные данные**: Словари Python со значениями конфигурации.

---

## 2. Сервис реестра моделей

Этот сервис отвечает за управление каталогом всех LLM, известных системе.

-   **Назначение**: Ведение реестра моделей, определенных в `llm_config.yml`, включая их метаданные и статус доступности.
-   **Ключевой компонент**: `ModelRegistry` (`src/llm/model_registry.py`).

### Бизнес-логика

-   При инициализации `ModelRegistry` загружает информацию о моделях (модель по умолчанию, альтернативные модели, их параметры) из `llm_config.yml` с помощью `ConfigManager`.
-   Он хранит эту информацию в виде списка объектов `ModelInfo`.
-   Реестр имеет метод `update_model_availability`, который принимает список моделей, реально доступных на сервере Ollama, и обновляет статус `is_available` для каждой модели в реестре.

### Использование

`ModelRegistry` обычно используется внутри `ModelLoader`, но может быть использован и отдельно для получения информации о моделях.

```python
from senana.langchain.src.llm.model_registry import ModelRegistry

# Инициализация
model_registry = ModelRegistry()

# Получение информации о модели по умолчанию
default_model_info = model_registry.get_model_info()

# Получение списка всех доступных моделей
available_models = model_registry.get_available_models()
```

-   **Входные данные**: `llm_config.yml` (через `ConfigManager`), список доступных на сервере моделей.
-   **Выходные данные**: Объекты `ModelInfo`, предоставляющие метаданные и статус моделей.

---

## 3. Сервис загрузки моделей

Это основной сервис для взаимодействия с Ollama. Он отвечает за создание и инициализацию экземпляров моделей.

-   **Назначение**: Подключение к серверу Ollama, проверка доступности моделей и загрузка их в виде объектов `langchain_ollama.OllamaLLM`.
-   **Ключевой компонент**: `ModelLoader` (`src/llm/model_loader.py`).

### Бизнес-логика

-   При инициализации `ModelLoader` проверяет доступность сервера Ollama.
-   Он запрашивает у сервера Ollama список загруженных моделей (`/api/tags`) и обновляет их статус в `ModelRegistry`.
-   Метод `load_model` является основной точкой входа. Он принимает имя модели и опциональные параметры.
-   Перед созданием экземпляра модели, он использует `ModelConfigurator` для сборки итоговой конфигурации.
-   Адаптирует параметры для совместимости с `OllamaLLM` и создает экземпляр модели.

### Использование

```python
from senana.langchain.src.llm.model_loader import ModelLoader

# Инициализация
model_loader = ModelLoader()

# Загрузка модели по умолчанию
llm = model_loader.load_model()

# Загрузка конкретной модели с кастомными параметрами
custom_params = {"temperature": 0.5, "top_k": 50}
llm_custom = model_loader.load_model("another-model:latest", model_params=custom_params)

if llm:
    response = llm.invoke("Why is the sky blue?")
    print(response)
```

-   **Входные данные**: Имя модели (опционально), словарь с параметрами для переопределения (опционально).
-   **Выходные данные**: Экземпляр `langchain_ollama.OllamaLLM` или `None` в случае ошибки.

---

## 4. Сервис конфигуратора моделей

Этот сервис является вспомогательным и отвечает за динамическую сборку конфигурации для конкретного экземпляра модели.

-   **Назначение**: Создание словаря с параметрами для инициализации модели, объединяя параметры по умолчанию, специфичные для модели и переданные пользователем.
-   **Ключевой компонент**: `ModelConfigurator` (`src/llm/model_configurator.py`).

### Бизнес-логика

-   `ModelConfigurator` получает информацию о модели из `ModelRegistry`.
-   Он создает конфигурацию, применяя параметры в следующем порядке (каждый следующий шаг может переопределить предыдущий):
    1.  Параметры по умолчанию из `llm_config.yml`.
    2.  Специфичные параметры для данной модели из `llm_config.yml`.
    3.  Параметры, переданные пользователем в метод `load_model` (`override_params`).
-   Метод `create_model_config` возвращает готовый словарь параметров.

### Использование

Этот сервис в основном используется внутри `ModelLoader`, и прямое взаимодействие с ним обычно не требуется.

-   **Входные данные**: Имя модели, `ModelRegistry`, опциональный словарь с параметрами.
-   **Выходные данные**: Словарь с итоговой конфигурацией для инициализации модели.
